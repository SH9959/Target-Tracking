# 前期搜集

![image-20221206224310733](草稿.assets/image-20221206224310733.png)

[cv2.KalmanFilter](https://github.com/jinwandou/-KalmanFilter-)函数原型

$x_k$：真实值，（一组状态向量）

$\hat x_k$：卡尔曼估计值

$P_k$：卡尔曼估计误差协方差矩阵

$\hat{x}_k'$：预测值

${P_k}'$：预测误差协方差矩阵

$K_k$：卡尔曼增益

$\hat{z}_k$：测量余量

$A$:状态转移矩阵

$u_k$:系统输入向量

$B$:输入增益矩阵

$\omega_k$:均值为0协方差矩阵为$Q$,服从正态分布的过程噪声

$H$:测量矩阵

$v_k$:均值为0协方差矩阵为$R$,服从正态分布的观测噪声

**卡尔曼计算过程:**

初始化：
$$
P_0,Q,R,B,u_k,A,\hat x'_0
$$
预测：
$$
\hat x'_k=A\hat x_{k-1}+Bu_k
\\P'_k=AP_{k-1}A^T+Q
$$
更新：
$$
K_k=P'_kH^T(HP'_kH^T+R)^{-1}
\\\hat x_k=\hat x_k'+K_k(z_k-H\hat x_k')
\\P_k=(I-K_kH)P'_k
$$



[目前经典跟踪算法](https://www.zhihu.com/question/26493945)：分生成和判别两类，卡尔曼是生成类

[KCF文章](https://arxiv.org/abs/1404.7584)

跟踪算法综述，[一个网站](http://cvlab.hanyang.ac.kr/tracker_benchmark/index.html)，Benchmark，可以下载数据集

一个关于综述的回答，链接：https://www.zhihu.com/question/26493945/answer/1654903369

[数据集](https://blog.csdn.net/laizi_laizi/article/details/105447947)

[救命稻草，光头男和绿色球的故事](https://blog.csdn.net/Miaosh999/article/details/106934655)

![image-20221210205215178](草稿.assets/image-20221210205215178.png)

[模型搭建参考](https://blog.csdn.net/qq_42500340/article/details/124476348)

![image-20221210210431125](草稿.assets/image-20221210210431125.png)



$$
\begin{cases} 
x_t=x_{t-1}+v_{x_{t-1}} \Delta t+\frac{1}{2}a_x\Delta t^2  \\
v_x=v_{x_{t-1}}+a_x\Delta t\\
y_t=y_{t-1}+v_{y_{t-1}} \Delta t+\frac{1}{2}a_y\Delta t^2  \\
v_y=v_{y_{t-1}}+a_y\Delta t\\
\end{cases}
$$

$$
u_k = [0]\\即\\
 \left[
 \begin{matrix}
   x_t\\
   v_{x_t}\\
   y_t\\
   v_{y_t}\\
   
  \end{matrix}
  \right] = \left[
 \begin{matrix}
   1 & 1 & 0 & 0 \\
   0 & 1 & 0 & 0 \\
   0 & 0 & 1 & 1 \\
   0 & 0 & 0 & 1
  \end{matrix}
  \right]  \left[
 \begin{matrix}
   x_{t-1}\\
   v_{x_{t-1}}\\
   y_{t-1}\\
   v_{y_{t-1}}\\
  \end{matrix}
  \right]
$$



## 单目标追踪

```python
#单目标追踪
import cv2
import sys
import time


if __name__ == '__main__' :

    # Set up tracker.
    # Instead of MIL, you can also use

    tracker_types = ['BOOSTING', 'MIL','KCF', 'TLD', 'MEDIANFLOW', 'GOTURN', 'MOSSE']
    tracker_type = tracker_types[2]

    if tracker_type == 'BOOSTING':
        tracker = cv2.TrackerBoosting_create()
    if tracker_type == 'MIL':
        tracker = cv2.TrackerMIL_create()
    if tracker_type == 'CSRT':
        tracker = cv2.TrackerCSRT_create()
    if tracker_type == 'KCF':
        tracker = cv2.TrackerKCF_create()
    if tracker_type == 'TLD':
        tracker = cv2.TrackerTLD_create()
    if tracker_type == 'MEDIANFLOW':
        tracker = cv2.TrackerMedianFlow_create()
    if tracker_type == 'GOTURN':
        tracker = cv2.TrackerGOTURN_create()
    #if tracker_type == 'MOSSE':
    #    tracker = cv2.TrackerMOSSE_create()

    # Read video
    video = cv2.VideoCapture("output.mp4")

    # Exit if video not opened.
    if not video.isOpened():
        print ("Could not open video")
        sys.exit()

    # Read first frame.
    ok, frame = video.read()
    if not ok:
        print ('Cannot read video file')
        sys.exit()

    # Define an initial bounding box
    bbox = (287, 23, 86, 320)

    # Uncomment the line below to select a different bounding box
    bbox = cv2.selectROI(frame, False)

    # Initialize tracker with first frame and bounding box
    ok = tracker.init(frame, bbox)

    while True:
        # Read a new frame
        ok, frame = video.read()
        if not ok:
            break

        # Start timer
        timer = cv2.getTickCount()

        # Update tracker
        ok, bbox = tracker.update(frame)

        # Calculate Frames per second (FPS)
        fps = cv2.getTickFrequency() / (cv2.getTickCount() - timer);

        # Draw bounding box
        if ok:
            # Tracking success
            p1 = (int(bbox[0]), int(bbox[1]))
            p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))
            cv2.rectangle(frame, p1, p2, (255,0,0), 2, 1)

        else :
            # Tracking failure
            cv2.putText(frame, "Tracking failure detected", (100,80), cv2.FONT_HERSHEY_SIMPLEX, 0.75,(0,0,255),2)

        # Display tracker type on frame
        cv2.putText(frame, tracker_type + " Tracker", (100,20), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (50,170,50),2);

        # Display FPS on frame
        cv2.putText(frame, "FPS : " + str(int(fps)), (100,50), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (50,170,50), 2);

        # Display result
        cv2.imshow("Tracking", frame)

        # Exit if ESC pressed
        k = cv2.waitKey(1) & 0xff
        if k == 27 : break
```

## 多目标追踪

```python

import numpy as np
import cv2
import sys
import time


# 打开摄像头，读取第一帧图像
cv2.namedWindow("tracking")
camera = cv2.VideoCapture('output.mp4')#videos/exam_small.mp4
ok_cam, image_pre = camera.read()
if not ok_cam:
    print('Failed to read video')
    exit()

img_h, img_w, c = image_pre.shape
image = cv2.resize(image_pre, (int(img_w/2), int(img_h/2)))

# 初始化num_obj个目标
num_obj = 20
bbox_list = []
tracker_list = []

for i in range(0, num_obj):
    bbox_tmp = cv2.selectROI('tracking', image)
    bbox_list.append(bbox_tmp)

    tracker_tmp = cv2.TrackerMOSSE_create()
    ok_tmp = tracker_tmp.init(image, bbox_tmp)
    tracker_list.append(tracker_tmp)


# 循环处理
while camera.isOpened():

    ok_cam, image_pre = camera.read()

    if not ok_cam:
        print ('no image to read')
        break

    img_h, img_w, c = image_pre.shape
    image = cv2.resize(image_pre, (int(img_w / 2), int(img_h / 2)))

    bbox_info = []

    # 更新跟踪结果
    pre = time.time()
    for tracker in tracker_list:
        ok_t, bbox_t = tracker.update(image)
        bbox_info.append((ok_t, bbox_t))
    print(time.time() - pre, '*********')

    # 在图像上显示跟踪结果
    for tmp_info in bbox_info:
        newbox = tmp_info[1]
        p1 = (int(newbox[0]), int(newbox[1]))
        p2 = (int(newbox[0] + newbox[2]), int(newbox[1] + newbox[3]))
        cv2.rectangle(image, p1, p2, (200,0,0))

    cv2.imshow('tracking', image)
    k = cv2.waitKey(1)
    if k == 27 : break # esc pressed
```

## 卡尔曼追踪手指

```python
# 开发作者   ：Tian.Z.L
# 开发时间   ：2022/4/26  9:52
# 文件名称   ：HandTrackingByKalman.PY
# 开发工具   ：PyCharm
import numpy as np
import mediapipe as mp
import cv2

print(cv2.useOptimized())
mpHands = mp.solutions.hands
hands = mpHands.Hands(static_image_mode=False,
                      max_num_hands=2,
                      min_detection_confidence=0.5,
                      min_tracking_confidence=0.5)
# 定义x的初始状态 -- 需要修改，初始化为捕获手势的位置x坐标
x_mat = np.mat([[0, ], [0, ]])
y_mat = np.mat([[0, ], [0, ]])
# 定义初始状态协方差矩阵
p_x_mat = np.mat([[1, 0], [0, 1]])
p_y_mat = np.mat([[1, 0], [0, 1]])
# 定义初始化控制矩阵
b_mat = np.mat([[0.5, ], [1, ]])
# 定义状态转移矩阵，因为每秒钟采一次样，所以delta_t = 1
f_mat = np.mat([[1, 1], [0, 1]])
# 定义状态转移协方差矩阵，这里我们把协方差设置的很小，因为觉得状态转移矩阵准确度高
q_mat = np.mat([[0.03, 0], [0, 0.03]])
# 定义观测矩阵
h_mat = np.mat([1, 1])
# 定义观测噪声协方差
r_mat = np.mat([1])

video = cv2.VideoCapture(0)#'output.avi'
first_frame_flag = True
while True:
    ret, frame = video.read()
    img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    results = hands.process(img)#处理RGB图像
    h, w, c = img.shape
    if results.multi_hand_landmarks:
        for handLms in results.multi_hand_landmarks:
            for id, lm in enumerate(handLms.landmark):
                cx, cy = int(lm.x * w), int(lm.y * h)
                if id == 12:
                    if first_frame_flag:
                        x_mat[0, 0] = cx
                        y_mat[0, 0] = cy
                        first_frame_flag = False
                    else:
                        x_predict = f_mat * x_mat
                        y_predict = f_mat * y_mat
                        p_x_predict = f_mat * p_x_mat * f_mat.T + q_mat
                        p_y_predict = f_mat * p_y_mat * f_mat.T + q_mat
                        kalman_x = p_x_predict * h_mat.T / (h_mat * p_x_predict * h_mat.T + r_mat)
                        kalman_y = p_y_predict * h_mat.T / (h_mat * p_y_predict * h_mat.T + r_mat)
                        x_mat = x_predict + kalman_x * (cx - h_mat * x_predict)
                        y_mat = y_predict + kalman_y * (cy - h_mat * y_predict)
                        p_x_mat = (np.eye(x_mat.shape[0]) - kalman_x * h_mat) * p_x_predict
                        p_y_mat = (np.eye(y_mat.shape[0]) - kalman_y * h_mat) * p_y_predict
                        noise_x = cx + int(np.random.normal(0, 1) * 10)
                        noise_y = cy + int(np.random.normal(0, 1) * 10)
                        cv2.circle(frame, (noise_x, noise_y), 6, (0, 0, 255), cv2.FILLED)
                        # cv2.circle(frame, (int(x_mat[0, 0]), int(y_mat[0, 0])), 3, (0, 255, 0), cv2.FILLED)
                        cv2.circle(frame, (int(x_mat[0, 0]), int(y_mat[0, 0])), 3, (255, 0, 0), cv2.FILLED)
                    break
    cv2.imshow('video', frame)
    if cv2.waitKey(20) & 0xFF == ord('q'):
        break
cv2.destroyAllWindows()
video.release()
```

## 手部识别

```python
import cv2
import mediapipe as mp

# mp.solutions.drawing_utils用于绘制
mp_drawing = mp.solutions.drawing_utils

# 参数：1、颜色，2、线条粗细，3、点的半径
DrawingSpec_point = mp_drawing.DrawingSpec((0, 255, 0), 1, 1)
DrawingSpec_line = mp_drawing.DrawingSpec((0, 0, 255), 1, 1)

# mp.solutions.hands，是人的手
mp_hands = mp.solutions.hands

# 参数：1、是否检测静态图片，2、手的数量，3、检测阈值，4、跟踪阈值
hands_mode = mp_hands.Hands(max_num_hands=2)

cap = cv2.VideoCapture(0)
while cap.isOpened():
    success, image = cap.read()
    if not success:
        print("Ignoring empty camera frame.")
        continue
    image1 = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

    # 处理RGB图像
    results = hands_mode.process(image1)

    # 绘制
    if results.multi_hand_landmarks:
        for hand_landmarks in results.multi_hand_landmarks:
            mp_drawing.draw_landmarks(
                image, hand_landmarks, mp_hands.HAND_CONNECTIONS, DrawingSpec_point, DrawingSpec_line)

    cv2.imshow('MediaPipe Hands', image)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

hands_mode.close()
cv2.destroyAllWindows()
cap.release()
```

## 两个普通卡尔曼

```python
import numpy as np
import matplotlib.pyplot as plt

"""
X(k) = AX(k-1) + BU(k) + w(k-1)
Z(k) = HX(k) + e(k)
p(w) = N(0, Q)
p(e) = N(0, R)
"""

def kf_predict(X0, P0, A, Q, B, U1):
    X10 = np.dot(A, X0) + np.dot(B, U1)
    P10 = np.dot(np.dot(A, P0), A.T) + Q
    return (X10, P10)

def kf_update(X10, P10, Z, H, R):
    V = Z - np.dot(H, X10)
    K = np.dot(np.dot(P10, H.T), np.linalg.pinv(np.dot(np.dot(H, P10), H.T) + R))
    X1 = X10 + np.dot(K, V)
    P1 = np.dot(np.eye(K.shape[0]) - np.dot(K, H), P10)
    return (X1, P1, K)


"""
加速度白噪声建模
状态方程：
x' = v'
v' = a'
a' = 0 
离散化得到；
x(k) = x(k-1)+t*v(k)+0.5*t^2*a(k)
v(k) = v(k-1)+t*a(k)
a(k) = a(k-1)

观测方程：
z(k) = x(k) + e

"""

n = 200  # 数据量
nx = 3  # 变量数量
t = np.linspace(0, 3, n)  # 时间序列
dt = t[1] - t[0]

# 实际函数关系
a_true = np.ones(n) * 9.8 + np.random.normal(0, 1, size=n)
v_true = np.cumsum(a_true * dt)
x_true = np.cumsum(v_true * dt)
X_true = np.concatenate([x_true, v_true, a_true]).reshape([nx, -1])
# 观测噪声协方差！！！！！！！！！！！！！！！！！！！！（可调整）
R = np.diag([10 ** 2])

# 仿真观测值
e = np.random.normal(0, 2, n)
x_obs = x_true + e

# 计算系数
A = np.array([1, dt, 0.5 * dt ** 2,
              0, 1, dt,
              0, 0, 1]).reshape([nx, nx])
B = 0
U1 = 0

# 状态假设（观测）初始值
x0 = 0
v0 = 0
a0 = 10.0
X0 = np.array([x0, v0, a0]).reshape(nx, 1)

# 初始状态不确定度（可调整）
P0 = np.diag([0 ** 2, 0 ** 2, 0.2 ** 2])

# 状态递推噪声协方差（可调整）
Q = np.diag([0.0 ** 2, 0 ** 2, 1 ** 2])

#开始处理
if __name__ == '__main__':
    plt.rcParams['font.sans-serif'] = ['SimHei']  # 设置图形里面中文为黑体
    X1_np = np.copy(X0)
    P1_list = [P0]
    X10_np = np.copy(X0)
    P10_list = [P0]

    for i in range(n):
        Zi = np.array(x_obs[i]).reshape([1, 1])
        Hi = np.array([1, 0, 0]).reshape([1, nx])
        if (i == 0):
            continue
        else:
            Xi = X1_np[:, i - 1].reshape([nx, 1])
            Pi = P1_list[i - 1]
            X10, P10 = kf_predict(Xi, Pi, A, Q, B, U1)

            X10_np = np.concatenate([X10_np, X10], axis=1)
            P10_list.append(P10)

            X1, P1, K = kf_update(X10, P10, Zi, Hi, R)
            X1_np = np.concatenate([X1_np, X1], axis=1)
            P1_list.append(P1)

    # 结束，绘图
    fig = plt.figure()
    ax1 = fig.add_subplot(1, 1, 1)
    ax1.plot(np.arange(n), x_true, 'k-', label="真实值")
    ax1.plot(np.arange(n), X1_np[0, :], 'g-', label="Kalman估计值")
    ax1.scatter(np.arange(n), x_obs, label="观测值", marker='.')
    ax1.set_xlabel('t')
    ax1.set_ylabel('x')
    plt.grid(ls='-.')
    plt.legend()
    plt.show()

'''import numpy as np
import pylab
import mediapipe as mp
import cv2

def KalmanFilter(z, n_iter=20):
    # 这里是假设A=1，H=1的情况
    # intial parameters
    sz = (n_iter,)  # size of array
    # Q = 1e-5 # process variance
    Q = 1e-6  # process variance
    # allocate space for arrays
    xhat = np.zeros(sz)  # a posteri estimate of x
    P = np.zeros(sz)  # a posteri error estimate
    xhatminus = np.zeros(sz)  # a priori estimate of x
    Pminus = np.zeros(sz)  # a priori error estimate
    K = np.zeros(sz)  # gain or blending factor
    R = 0.1 ** 2  # estimate of measurement variance, change to see effect
    # intial guesses
    xhat[0] = 0.0
    P[0] = 1.0
    A = 1
    H = 1
    for k in range(1, n_iter):
        # time update
        xhatminus[k] = A * xhat[k - 1]  # X(k|k-1) = AX(k-1|k-1) + BU(k) + W(k),A=1,BU(k) = 0
        Pminus[k] = A * P[k - 1] + Q  # P(k|k-1) = AP(k-1|k-1)A' + Q(k) ,A=1

        # measurement update
        K[k] = Pminus[k] / (Pminus[k] + R)  # Kg(k)=P(k|k-1)H'/[HP(k|k-1)H' + R],H=1
        xhat[k] = xhatminus[k] + K[k] * (z[k] - H * xhatminus[k])  # X(k|k) = X(k|k-1) + Kg(k)[Z(k) - HX(k|k-1)], H=1
        P[k] = (1 - K[k] * H) * Pminus[k]  # P(k|k) = (1 - Kg(k)H)P(k|k-1), H=1
    return xhat


if __name__ == '__main__':
    pylab.rcParams['font.sans-serif'] = ['SimHei']  # 设置图形里面中文为黑体
    txt = ['1.txt', 'raw_data.txt']
    with open(txt[0], "r", encoding="utf-8") as f:
        text = f.readlines()
    #print(text)
    raw_data = []
    for x in text:
        raw_data.append(int(x))
        #print(int(x))
    xhat = KalmanFilter(raw_data, n_iter=len(raw_data))
    pylab.plot(raw_data, 'k-', label='观测')  # 测量值
    pylab.plot(xhat, 'b-', label='卡尔曼估计')  # 过滤后的值
    pylab.legend()
    pylab.xlabel('x')
    pylab.ylabel('y')
    pylab.grid(ls='-.')
    pylab.title('test')
    pylab.show()'''
```

## 二值化示例

```python
# -*- coding: utf-8 -*-
"""
Created on Fri Sep 22 21:54:34 2017

@author: shigan
"""

import cv2
#相对路径下读取图片
doge = cv2.imread('doge.jpg')
#灰度化处理
grayImage = cv2.cvtColor(doge,cv2.COLOR_BGR2GRAY)
#cv2.imshow('GRAY',grayImage)

#二值化处理，低于阈值的像素点灰度值置为0；高于阈值的值置为参数3
ret,thresh1 = cv2.threshold(grayImage,127,255,cv2.THRESH_BINARY)
cv2.imshow('BINARY',thresh1)


#大于阈值的像素点灰度值置为0；小于阈值置为参数3
ret,thresh2 = cv2.threshold(grayImage,127,200,cv2.THRESH_BINARY_INV)
cv2.imshow('BINARY_INV',thresh2)

#小于阈值的像素点灰度值不变，大于阈值的像素点置为该阈值
ret,thresh3 = cv2.threshold(grayImage,127,255,cv2.THRESH_TRUNC)
cv2.imshow('TRUNC',thresh3)

#小于阈值的像素点灰度值不变，大于阈值的像素点置为0,其中参数3任取
ret,thresh4 = cv2.threshold(grayImage,127,255,cv2.THRESH_TOZERO)
cv2.imshow('BINARY_TOZERO',thresh4)


#大于阈值的像素点灰度值不变，小于阈值的像素点置为0,其中参数3任取
ret,thresh5 = cv2.threshold(grayImage,127,255,cv2.THRESH_TOZERO_INV)
cv2.imshow('BINARY_TOZERO_INV',thresh5)
```

## ROI

```python
image=cv2.imread('example.png')
cv2.namedWindow('img')
r = cv2.selectROI('roi', image, False, False )
print(r)
img_roi = image[int(r[1]):int(r[1]+r[3]),int(r[0]):int(r[0]+r[2])] 
cv2.imshow("imageHSV",img_roi)
cv2.waitKey(0)
```

## KalmanFilter类

来自[最细解读](https://blog.csdn.net/u010712012/article/details/90294295?utm_medium=distribute.pc_relevant.none-task-blog-baidujs-2)

```python
class KalmanBoxTracker(object): #Kalman滤波的实现
  """
  This class represents the internel state of individual tracked objects observed as bbox.
  """
  count = 0
  def __init__(self,bbox):
    """
    Initialises a tracker using initial bounding box.
    """
    #define constant velocity model
    self.kf = KalmanFilter(dim_x=7, dim_z=4)
    self.kf.F = np.array([[1,0,0,0,1,0,0],[0,1,0,0,0,1,0],[0,0,1,0,0,0,1],[0,0,0,1,0,0,0],  [0,0,0,0,1,0,0],[0,0,0,0,0,1,0],[0,0,0,0,0,0,1]])
    self.kf.H = np.array([[1,0,0,0,0,0,0],[0,1,0,0,0,0,0],[0,0,1,0,0,0,0],[0,0,0,1,0,0,0]])
    self.kf.R[2:,2:] *= 10.
    self.kf.P[4:,4:] *= 1000. #give high uncertainty to the unobservable initial velocities
    self.kf.P *= 10.
    self.kf.Q[-1,-1] *= 0.01
    self.kf.Q[4:,4:] *= 0.01
    self.kf.x[:4] = convert_bbox_to_z(bbox)
    self.time_since_update = 0
    self.id = KalmanBoxTracker.count
    KalmanBoxTracker.count += 1
    self.history = []
    self.hits = 0
    self.hit_streak = 0
    self.age = 0 
  def update(self,bbox):
    """
    Updates the state vector with observed bbox.
    """
    self.time_since_update = 0
    self.history = []
    self.hits += 1
    self.hit_streak += 1
    self.kf.update(convert_bbox_to_z(bbox))
  def predict(self):
    """
    Advances the state vector and returns the predicted bounding box estimate.
    """
    if((self.kf.x[6]+self.kf.x[2])<=0):
      self.kf.x[6] *= 0.0
    self.kf.predict()
    self.age += 1
    if(self.time_since_update>0):
      self.hit_streak = 0
    self.time_since_update += 1
    self.history.append(convert_x_to_bbox(self.kf.x))
    return self.history[-1]
  def get_state(self):
    """
    Returns the current bounding box estimate.
    """
    return convert_x_to_bbox(self.kf.x)
```

## 我们的代码

```python
import cv2
import numpy as np
import matplotlib.pyplot as plt

class KFT():
    """
    一个卡尔曼滤波追踪器KalmanFilterTracker
    """
    count = 0

    def __init__(self,  A = np.array([[1,1,0,0],
                                      [0,1,0,0],
                                      [0,0,1,1],
                                      [0,0,0,1]]),
                        B = np.array([0.5,1,0.5,1]),
                        R = np.array([[0.1,0,0,0],
                                      [0,0.1,0,0],
                                      [0,0,0.1,0],
                                      [0,0,0,0.1]]),
                        Q = np.array([[0.1,0,0,0],
                                      [0,0.1,0,0],
                                      [0,0,0.1,0],
                                      [0,0,0,0.1]]),
                        H = np.eye(4),
                        U = np.array([0,0,0,0]),
                        P = np.array([[0.1,0,0,0],
                                      [0,0.1,0,0],
                                      [0,0,0.1,0],
                                      [0,0,0,0.1]]),
                        P1= np.array([[0.1,0,0,0],
                                      [0,0.1,0,0],
                                      [0,0,0.1,0],
                                      [0,0,0,0.1]]),
                        K = np.array([0]),
                        X = np.array([0,0,0,0]),
                        X1= np.array([0,0,0,0])):

        self.id = KFT.count
        KFT.count += 1
        self.A = A
        self.B = B
        self.R = R
        self.Q = Q
        self.H = H
        self.U = U

        self.P = P
        self.P1= P1
        self.K = K
        self.X = X
        self.X1= X1

        self.X_all = [X]
        self.X1_all = [X1]

    def predict(self):
#        print('-----------------------------------------------------------')

        self.X1 = np.dot(self.A, self.X_all[-1]) + np.dot(self.B, self.U)
#        print('X1:\n', self.X1)
        self.P1 = np.dot(np.dot(self.A, self.P), self.A.T) + self.Q
#        print('P1:\n',self.P1)
        self.X1_all.append(self.X1)
        return (self.X1, self.P1)

    def update(self, Z):#输入观测状态向量[x,0,y,0]
        self.K = np.dot(np.dot(self.P1, self.H.T), np.linalg.pinv(np.dot(np.dot(self.H, self.P1), self.H.T) + self.R))
#        print('K:\n', self.K)
#        print(np.dot(self.P1, self.H.T))
#        print('*')
#        print(np.dot(self.H, self.P1))
#        print(np.dot(np.dot(self.H, self.P1), self.H.T))
#        print(np.dot(np.dot(self.H, self.P1), self.H.T) + self.R)
#        print(np.linalg.pinv(np.dot(np.dot(self.H, self.P1), self.H.T) + self.R))


        self.X = self.X1 + np.dot(self.K, Z - np.dot(self.H, self.X1))
#        print('X:\n', self.X)
        self.P = np.dot(np.eye(self.K.shape[0]) - np.dot(self.K, self.H), self.P1)
#        print('P:\n', self.P)
        self.X_all.append(self.X)
#        print('-----------------------------------------------------------')
        return (self.X, self.P, self.K)

    def getX(self):
        return self.X_all

if __name__ == '__main__':
    data = []
    with open('1.txt') as f:
        for line in f:
            data.append([int(x) for x in line.split(",")])
    data = np.array(data)
#    print(data)
    x0 = np.array([data[0][0], 2, data[0][1], 2])  # 初始位置
    kft = KFT(X = x0)
#    print(kft.id)
    for i in range(1,len(data)):
        kft.predict()
        x = np.array([data[i][0], 2+i/20, data[i][1], 2+i/20])
        kft.update(Z=x)
    XX = kft.getX()
    X = [z[0] for z in XX]
    Y = [z[2] for z in XX]
#    print(XX)

    plt.figure('ss')
    plt.plot(data.T[0], data.T[1])
    plt.plot(X, Y)
    plt.grid(ls='-.')
    plt.show()
```

## 获取指定像素位置

```python
import numpy as np
from PIL import Image 

image = Image.open("tqc.jpg")
pixels = np.asarray(image)
# Set threshold level
threshold_level = 50
# Find coordinates of all pixels below threshold
coords = np.column_stack(np.where(pixels < threshold_level))
print(coords)
```

## 我写的卡尔曼类

```python
import cv2
import numpy as np
import matplotlib.pyplot as plt

class KFT():
    """
    一个卡尔曼滤波追踪器KalmanFilterTracker
    """
    count = 0

    def __init__(self,  A = np.array([[1,1,0,0],
                                      [0,1,0,0],
                                      [0,0,1,1],
                                      [0,0,0,1]]),
                        B = np.array([0.5,1,0.5,1]),
                        R = np.array([[0.1,0,0,0],
                                      [0,0.1,0,0],
                                      [0,0,0.1,0],
                                      [0,0,0,0.1]]),
                        Q = np.array([[0.1,0,0,0],
                                      [0,0.1,0,0],
                                      [0,0,0.1,0],
                                      [0,0,0,0.1]]),
                        H = np.eye(4),
                        U = np.array([0,0,0,0]),
                        P = np.array([[0.1,0,0,0],
                                      [0,0.1,0,0],
                                      [0,0,0.1,0],
                                      [0,0,0,0.1]]),
                        P1= np.array([[0.1,0,0,0],
                                      [0,0.1,0,0],
                                      [0,0,0.1,0],
                                      [0,0,0,0.1]]),
                        K = np.array([0]),
                        X = np.array([0,0,0,0]),
                        X1= np.array([0,0,0,0])):

        self.id = KFT.count
        KFT.count += 1
        self.A = A
        self.B = B
        self.R = R
        self.Q = Q
        self.H = H
        self.U = U

        self.P = P
        self.P1= P1
        self.K = K
        self.X = X
        self.X1= X1

        self.X_all = [X]
        self.X1_all = [X1]

    def predict(self):
#        print('-----------------------------------------------------------')

        self.X1 = np.dot(self.A, self.X_all[-1]) + np.dot(self.B, self.U)
#        print('X1:\n', self.X1)
        self.P1 = np.dot(np.dot(self.A, self.P), self.A.T) + self.Q
#        print('P1:\n',self.P1)
        self.X1_all.append(self.X1)
        return (self.X1, self.P1)

    def update(self, Z):#输入观测状态向量[x,0,y,0]
        self.K = np.dot(np.dot(self.P1, self.H.T), np.linalg.pinv(np.dot(np.dot(self.H, self.P1), self.H.T) + self.R))
#        print('K:\n', self.K)
#        print(np.dot(self.P1, self.H.T))
#        print('*')
#        print(np.dot(self.H, self.P1))
#        print(np.dot(np.dot(self.H, self.P1), self.H.T))
#        print(np.dot(np.dot(self.H, self.P1), self.H.T) + self.R)
#        print(np.linalg.pinv(np.dot(np.dot(self.H, self.P1), self.H.T) + self.R))


        self.X = self.X1 + np.dot(self.K, Z - np.dot(self.H, self.X1))
#        print('X:\n', self.X)
        self.P = np.dot(np.eye(self.K.shape[0]) - np.dot(self.K, self.H), self.P1)
#        print('P:\n', self.P)
        self.X_all.append(self.X)
#        print('-----------------------------------------------------------')
        return (self.X, self.P, self.K)

    def getX(self):
        return self.X_all

if __name__ == '__main__':
    plt.rcParams['font.sans-serif'] = ['SimHei']  # 设置图形里面中文为黑体
    data = []
    with open('1.txt') as f:
        for line in f:
            data.append([int(x) for x in line.split(",")])
    data = np.array(data)
    print(data)
    x0 = np.array([data[0][0], 0, data[0][1], 0])  # 初始位置
    kft = KFT(X = x0)
#    print(kft.id)
    x = x0
    for i in range(1,len(data)):
        (x1, p1) = kft.predict()
        vx = data[i][0] - data[i-1][0]
        vy = data[i][1] - data[i-1][1]
        z = np.array([data[i][0], vx, data[i][1], vy])
        (x, p, k) = kft.update(Z=z)
    XX = kft.getX()
    X = [z[0] for z in XX]
    Y = [z[2] for z in XX]
#    print(XX)

    plt.figure('ss')
    plt.plot(data.T[0], data.T[1])
    plt.plot(X, Y)
    plt.grid(ls='-.')
    plt.legend(['观测', 'KF估计'])
    plt.show()
```

## 我写的失败的代码

算法思想：

每传入一帧，首先对ROI二值化，计算出ROI区域内的边缘，计算出边缘包裹的内容的质心，作为当前观测值传入卡尔曼。

```python
import cv2
import numpy as np
import matplotlib.pyplot as plt
import math
import sys
from collections import  deque
class KFT():
    """
    一个卡尔曼滤波追踪器KalmanFilterTracker
    """
    count = 0

    def __init__(self,  A = np.array([[1,1,0,0],
                                      [0,1,0,0],
                                      [0,0,1,1],
                                      [0,0,0,1]]),
                        B = np.array([0.5,1,0.5,1]),
                        R = np.array([[0.1,0,0,0],
                                      [0,0.1,0,0],
                                      [0,0,0.1,0],
                                      [0,0,0,0.1]]),
                        Q = np.array([[0.1,0,0,0],
                                      [0,0.1,0,0],
                                      [0,0,0.1,0],
                                      [0,0,0,0.1]]),
                        H = np.eye(4),
                        U = np.array([0,0,0,0]),
                        P = np.array([[0.1,0,0,0],
                                      [0,0.1,0,0],
                                      [0,0,0.1,0],
                                      [0,0,0,0.1]]),
                        P1= np.array([[0.1,0,0,0],
                                      [0,0.1,0,0],
                                      [0,0,0.1,0],
                                      [0,0,0,0.1]]),
                        K = np.array([0]),
                        X = np.array([0,0,0,0]),
                        X1= np.array([0,0,0,0])):

        self.id = KFT.count
        KFT.count += 1
        self.A = A
        self.B = B
        self.R = R
        self.Q = Q
        self.H = H
        self.U = U

        self.P = P
        self.P1= P1
        self.K = K
        self.X = X
        self.X1= X1

        self.X_all = [X]
        self.X1_all = [X1]

    def predict(self):
#        print('-----------------------------------------------------------')

        self.X1 = np.dot(self.A, self.X_all[-1]) + np.dot(self.B, self.U)
#        print('X1:\n', self.X1)
        self.P1 = np.dot(np.dot(self.A, self.P), self.A.T) + self.Q
#        print('P1:\n',self.P1)
        self.X1_all.append(self.X1)
        return (self.X1, self.P1)

    def update(self, Z):#输入观测状态向量[x,0,y,0]
        self.K = np.dot(np.dot(self.P1, self.H.T), np.linalg.pinv(np.dot(np.dot(self.H, self.P1), self.H.T) + self.R))
#        print('K:\n', self.K)
#        print(np.dot(self.P1, self.H.T))
#        print('*')
#        print(np.dot(self.H, self.P1))
#        print(np.dot(np.dot(self.H, self.P1), self.H.T))
#        print(np.dot(np.dot(self.H, self.P1), self.H.T) + self.R)
#        print(np.linalg.pinv(np.dot(np.dot(self.H, self.P1), self.H.T) + self.R))


        self.X = self.X1 + np.dot(self.K, Z - np.dot(self.H, self.X1))
#        print('X:\n', self.X)
        self.P = np.dot(np.eye(self.K.shape[0]) - np.dot(self.K, self.H), self.P1)
#        print('P:\n', self.P)
        self.X_all.append(self.X)
#        print('-----------------------------------------------------------')
        return (self.X, self.P, self.K)

    def getX(self):
        return self.X_all

def GetFirstPositionFromFrame(frame):
    img_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  # 得到灰度图
    r = cv2.selectROI('roi', img_gray, False, False)
    # print(r)
    #img_roi = img_gray[int(r[1]):int(r[1] + r[3]), int(r[0]):int(r[0] + r[2])]

    print('bk')

    # cv2.imshow("imagegray", img_roi)
    z0 = np.array([int(r[1] + math.ceil(r[3]/2)), int(r[0] + math.ceil(r[2]/2))])
    h = int(r[3])
    w = int(r[2])

    print('", Line '+str(sys._getframe().f_lineno))

    return [z0, h, w]#返回初始坐标，以及roi框的大小

def GetPositonFromFrame(frame,xy1,h1, w1):#得到观测位置,输入预测位置xy1以选定搜索区域,h1是该区域高度的一半，w1是该区域宽度的一半
    lu = [xy1[0] - h1, xy1[1] - w1, 2*h1, 2*w1]#z左上角
    lu = [int(x) for x in lu]#整数化
    img_roi = frame[int(lu[1]):int(lu[1] + lu[3]), int(lu[0]):int(lu[0] + lu[2])]

    #plt.imshow(img_roi)
    print('", Line ' + str(sys._getframe().f_lineno))

    img_gray = cv2.cvtColor(img_roi, cv2.COLOR_BGR2GRAY)#得到灰度图
    # Otsu 滤波
    print('", Line ' + str(sys._getframe().f_lineno))
    ret, binary = cv2.threshold(img_gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)#大津分割
    print('", Line ' + str(sys._getframe().f_lineno))
    contours, hierarchy = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)  # 只检测外部轮廓，保存物体边界上所有连续的轮廓点到contours向量内
    #testimg = np.zeros((2 * h1, 2 * w1), dtype=np.uint8)  # 全黑图片
    print(contours)
    print('len:\n',len(contours))
    suma = []#用来求质心
    sumb = []#用来求质心

    if len(contours)>1:
        for i in range(len(contours)):
            max = -1
            if len(contours[i])>max:
                max = len(contours[i])
                contour = contours[i]#取最大的一个


    for a in range(2*h1):
        for b in range(2*w1):
            #############################################辨别是否在轮廓内是定义为1，不是定义为-1
            result = cv2.pointPolygonTest(contour, (a, b), False)
            if result > 0:
                #testimg[b, a] = 255
                suma.append(a)
                sumb.append(b)
    #plt.plot(testimg)
    z = [math.ceil(sum(suma)/len(suma)) + lu[0], math.ceil(sum(sumb)/len(sumb)) + lu[1]]#质心坐标[h, w]
    return z

#初始化追踪点的列表
mybuffer = 64
pts = deque(maxlen=mybuffer)

if __name__ == '__main__':
    video = cv2.VideoCapture(0)
    print('", Line ' + str(sys._getframe().f_lineno))
    # Exit if video not opened.
    if not video.isOpened():
        print("Could not open video")
        sys.exit()
    # Read first frame.
    ok, frame1 = video.read()
    print('", Line ' + str(sys._getframe().f_lineno))
    if not ok:
        print('Cannot read video file')
        sys.exit()
    frame = np.copy(frame1)
    [z0, h, w] = GetFirstPositionFromFrame(frame)
    h1 = math.ceil(h/2) + 20
    w1 = math.ceil(w/2) + 20
    print('", Line ' + str(sys._getframe().f_lineno))
    kft = KFT(X=np.array([z0[0], 1, z0[1], 1]))#传入第一帧
    print('", Line ' + str(sys._getframe().f_lineno))

    print('", Line ' + str(sys._getframe().f_lineno))
    lastZxy = np.array(list(z0))
    print('", Line ' + str(sys._getframe().f_lineno))
    while(video.isOpened()):
        print('", Line ' + str(sys._getframe().f_lineno))
        ok, frame1 = video.read()
        frame = np.copy(frame1)
        [x1, p1] = kft.predict()
        print([x1, p1])
        print('", Line ' + str(sys._getframe().f_lineno))
        print([x1[0], x1[2]])
        Zxy = GetPositonFromFrame(frame, [x1[0], x1[2]], h1, w1)#在预测值范围内搜索，得到质心坐标
        print('", Line ' + str(sys._getframe().f_lineno))
        Vh = Zxy[0] - lastZxy[0]
        print('", Line ' + str(sys._getframe().f_lineno))
        Vw = Zxy[1] - lastZxy[1]
        print('", Line ' + str(sys._getframe().f_lineno))
        lastZxy = list(Zxy)
        kft.update([Zxy[0], Vh, Zxy[1], Vw])

        #绘图
        X = kft.getX()
        x, y = X[-1][0], X[-1][2]
        center = (int(x), int(y))
        print(center)
        cv2.circle(frame1, center, 5, (0, 0, 255), -1)
        print('", Line ' + str(sys._getframe().f_lineno))
        # 把质心添加到pts中，并且是添加到列表左侧
        pts.appendleft(center)
        for i in range(1, len(pts)):
            if pts[i - 1] is None or pts[i] is None:
                continue
            # 计算所画小线段的粗细
            thickness = int(np.sqrt(mybuffer / float(i + 1)) * 2.5)
            # 画出小线段
            cv2.line(frame1, pts[i - 1], pts[i], (0, 0, 255), thickness)
        # res = cv2.bitwise_and(frame, frame, mask=mask)
        cv2.imshow('Frame', frame1)
        # 键盘检测，检测到esc键退出
        print('", Line ' + str(sys._getframe().f_lineno))
        k = cv2.waitKey(5) & 0xFF
        if k == 27:
            break
    # 摄像头释放
    video.release()
    # 销毁所有窗口
    cv2.destroyAllWindows()

   """ 
    data = []
    with open('1.txt') as f:
        for line in f:
            data.append([int(x) for x in line.split(",")])
    data = np.array(data)
#    print(data)
    x0 = np.array([data[0][0], 2, data[0][1], 2])  # 初始位置
    kft = KFT(X = x0)
#    print(kft.id)
    for i in range(1, len(data)):
        kft.predict()
        x = np.array([data[i][0], 2+i/20, data[i][1], 2+i/20])
        kft.update(Z=x)
    XX = kft.getX()
    X = [z[0] for z in XX]
    Y = [z[2] for z in XX]
#    print(XX)
    plt.figure('ss')
    plt.plot(data.T[0], data.T[1])
    plt.plot(X, Y)
    plt.grid(ls='-.')
    plt.show()
    """
    
```

## 阈值代码

```python
from collections import  deque
import numpy as np
import cv2
# imutils
import time
#设定阈值，HSV空间
redLower = np.array([35, 43, 46])
redUpper = np.array([100, 255, 255])
#初始化追踪点的列表
mybuffer = 64
pts = deque(maxlen=mybuffer)
#打开摄像头
camera = cv2.VideoCapture(0)

#等待两秒
time.sleep(2)
#遍历每一帧，检测红色瓶盖
while True:
    #读取帧
    (ret, frame) = camera.read()
    if ret == False:
        break
    #判断是否成功打开摄像头
    # if not ret:
    #     print('No Camera')
    #     break
    #frame = imutils.resize(frame, width=600)
    #转到HSV空间
    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
    #根据阈值构建掩膜
    mask = cv2.inRange(hsv, redLower, redUpper)
    #腐蚀操作
    mask = cv2.erode(mask, None, iterations=2)
    #膨胀操作，其实先腐蚀再膨胀的效果是开运算，去除噪点
    mask = cv2.dilate(mask, None, iterations=2)
    #轮廓检测
    cnts = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[-2]
    #初始化瓶盖圆形轮廓质心
    center = None
    #如果存在轮廓
    if len(cnts) > 0:
        #找到面积最大的轮廓
        c = max(cnts, key = cv2.contourArea)
        #确定面积最大的轮廓的外接圆
        ((x, y), radius) = cv2.minEnclosingCircle(c)
        #计算轮廓的矩
        M = cv2.moments(c)
        #计算质心
        center = (int(M["m10"]/M["m00"]), int(M["m01"]/M["m00"]))
        #只有当半径大于10时，才执行画图
        if radius > 10:
            cv2.circle(frame, (int(x), int(y)), int(radius), (0, 255, 255), 2)
            cv2.circle(frame, center, 5, (0, 0, 255), -1)
            #把质心添加到pts中，并且是添加到列表左侧
            pts.appendleft(center)
    #遍历追踪点，分段画出轨迹
    for i in range(1, len(pts)):
        if pts[i - 1] is None or pts[i] is None:
            continue
        #计算所画小线段的粗细
        thickness = int(np.sqrt(mybuffer / float(i + 1)) * 2.5)
        #画出小线段
        cv2.line(frame, pts[i - 1], pts[i], (0, 0, 255), thickness)
    #res = cv2.bitwise_and(frame, frame, mask=mask)
    cv2.imshow('Frame', frame)
    #键盘检测，检测到esc键退出
    k = cv2.waitKey(5)&0xFF
    if k == 27:
        break
#摄像头释放
camera.release()
#销毁所有窗口
cv2.destroyAllWindows()
```

## *利用我的卡尔曼和阈值结合（simple）

```python
import cv2
import numpy as np
import matplotlib.pyplot as plt
from collections import deque
import time

iswrite = False#是否保存写入

class KFT():
    """
    一个卡尔曼滤波追踪器KalmanFilterTracker
    """
    count = 0

    def __init__(self, A=np.array([[1, 1, 0, 0],
                                   [0, 1, 0, 0],
                                   [0, 0, 1, 1],
                                   [0, 0, 0, 1]]),
                 B=np.array([0.5, 1, 0.5, 1]),
                 R=np.array([[0.1, 0, 0, 0],
                             [0, 0.1, 0, 0],
                             [0, 0, 0.1, 0],
                             [0, 0, 0, 0.1]]),
                 Q=np.array([[0.1, 0, 0, 0],
                             [0, 0.1, 0, 0],
                             [0, 0, 0.1, 0],
                             [0, 0, 0, 0.1]]),
                 H=np.eye(4),
                 U=np.array([0, 0, 0, 0]),
                 P=np.array([[0.1, 0, 0, 0],
                             [0, 0.1, 0, 0],
                             [0, 0, 0.1, 0],
                             [0, 0, 0, 0.1]]),
                 P1=np.array([[0.1, 0, 0, 0],
                              [0, 0.1, 0, 0],
                              [0, 0, 0.1, 0],
                              [0, 0, 0, 0.1]]),
                 K=np.array([0]),
                 X=np.array([0, 0, 0, 0]),
                 X1=np.array([0, 0, 0, 0])):
        self.id = KFT.count
        KFT.count += 1
        self.A = A
        self.B = B
        self.R = R
        self.Q = Q
        self.H = H
        self.U = U

        self.P = P
        self.P1 = P1
        self.K = K
        self.X = X
        self.X1 = X1

        self.X_all = [X]
        self.X1_all = [X1]

    def predict(self):
        #        print('-----------------------------------------------------------')

        self.X1 = np.dot(self.A, self.X_all[-1]) + np.dot(self.B, self.U)
        #        print('X1:\n', self.X1)
        self.P1 = np.dot(np.dot(self.A, self.P), self.A.T) + self.Q
        #        print('P1:\n',self.P1)
        self.X1_all.append(self.X1)
        return (self.X1, self.P1)

    def update(self, Z):  # 输入观测状态向量[x,0,y,0]
        self.K = np.dot(np.dot(self.P1, self.H.T), np.linalg.pinv(np.dot(np.dot(self.H, self.P1), self.H.T) + self.R))
        #        print('K:\n', self.K)
        #        print(np.dot(self.P1, self.H.T))
        #        print('*')
        #        print(np.dot(self.H, self.P1))
        #        print(np.dot(np.dot(self.H, self.P1), self.H.T))
        #        print(np.dot(np.dot(self.H, self.P1), self.H.T) + self.R)
        #        print(np.linalg.pinv(np.dot(np.dot(self.H, self.P1), self.H.T) + self.R))

        self.X = self.X1 + np.dot(self.K, Z - np.dot(self.H, self.X1))
        #        print('X:\n', self.X)
        self.P = np.dot(np.eye(self.K.shape[0]) - np.dot(self.K, self.H), self.P1)
        #        print('P:\n', self.P)
        self.X_all.append(self.X)
        #        print('-----------------------------------------------------------')
        return (self.X, self.P, self.K)

    def getX(self):
        return self.X_all


if __name__ == '__main__':
    plt.rcParams['font.sans-serif'] = ['SimHei']  # 设置图形里面中文为黑体
    
    OB = [[], []]  # 记录观测数据
    ES = [[], []]  # 记录估计数据
    # 设定阈值，HSV空间
    orange = [[7, 172, 87], [21, 255, 255]]

    redLower = np.array(orange[0])
    redUpper = np.array(orange[1])
    # 初始化追踪点的列表
    mybuffer = 64
    pts = deque(maxlen=mybuffer)
    # 打开摄像头
    camera = cv2.VideoCapture('test.mp4')  # 'test.mp4'
    # 保存视频
    width = int(camera.get(cv2.CAP_PROP_FRAME_WIDTH))  # 获取视频的宽度
    height = int(camera.get(cv2.CAP_PROP_FRAME_HEIGHT))  # 获取视频的高度
    fps = camera.get(cv2.CAP_PROP_FPS)  # 获取视频的帧率
    fourcc = int(camera.get(cv2.CAP_PROP_FOURCC))  # 视频的编码
    # 定义视频对象输出
    if iswrite:
        writer = cv2.VideoWriter("result.mp4", fourcc, fps, (width, height))#200

    # 等待两秒
    time.sleep(2)
    # 遍历每一帧，检测红色瓶盖
    cnt = 0
    while True:
        # 读取帧
        (ret, frame) = camera.read()
        if ret == False:
            break
        timer = cv2.getTickCount()
        # 判断是否成功打开摄像头
        # if not ret:
        #     print('No Camera')
        #     break
        # frame = imutils.resize(frame, width=600)
        # 转到HSV空间
        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
        # 根据阈值构建掩膜
        mask = cv2.inRange(hsv, redLower, redUpper)
        # 腐蚀操作
        mask = cv2.erode(mask, None, iterations=2)
        # 膨胀操作，其实先腐蚀再膨胀的效果是开运算，去除噪点
        mask = cv2.dilate(mask, None, iterations=2)
        # 轮廓检测
        cnts = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[-2]
        # 初始化瓶盖圆形轮廓质心
        center = None
        # 如果存在轮廓
        if len(cnts) > 0:
            # 找到面积最大的轮廓
            c = max(cnts, key=cv2.contourArea)
            # 确定面积最大的轮廓的外接圆
            ((x, y), radius) = cv2.minEnclosingCircle(c)
            # 计算轮廓的矩
            M = cv2.moments(c)
            # 计算质心
            center = (int(M["m10"] / M["m00"]), int(M["m01"] / M["m00"]))  # center为观测值
            OB[0].append(center[0])
            OB[1].append(center[1])

            if cnt == 0:  # 如果是首帧
                x0 = np.array([center[0], 0, center[1], 0])  # 初始位置
                kft = KFT(X=x0)
                lastx = center[0]
                lasty = center[1]
                cnt += 1
                continue

            (X1, P1) = kft.predict()
            vx = center[0] - lastx
            vy = center[1] - lasty
            z = np.array([center[0], vx, center[1], vy])
            (X, P, K) = kft.update(Z=z)

            # X就是最优估计

            lastx = center[0]
            lasty = center[1]

            esX = X[0]
            esY = X[2]

            ES[0].append(esX)
            ES[1].append(esY)
            # 只有当半径大于10时，才执行画图
            if radius > 10:
                cv2.circle(frame, (int(x), int(y)), int(radius), (0, 255, 255), 2)
                cv2.circle(frame, center, 2, (0, 0, 255), -1)
                cv2.circle(frame, (int(esX), int(esY)), 2, (0, 0, 0), -1)  # 最优估计

                # 把质心添加到pts中，并且是添加到列表左侧
                pts.appendleft(center)
        """
                for i in range(1, len(pts)):
            if pts[i - 1] is None or pts[i] is None:
                continue
            # 计算所画小线段的粗细
            thickness = int(np.sqrt(mybuffer / float(i + 1)) * 2.5)
            # 画出小线段
            cv2.line(frame, pts[i - 1], pts[i], (0, 0, 255), thickness)
        # res = cv2.bitwise_and(frame, frame, mask=mask)
        """
        # 遍历追踪点，分段画出轨迹
        fps = cv2.getTickFrequency() / (cv2.getTickCount() - timer)
        cv2.putText(frame, "FPS : " + str(int(fps)), (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (50, 170, 50), 1)
        # cv2.putText(frame, ":kalman est " + str(int(fps)), (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 0), 1)
        cv2.imshow('Frame', frame)
        if iswrite:
            writer.write(frame)  # 视频保存
        # 键盘检测，检测到esc键退出
        k = cv2.waitKey(5) & 0xFF
        if k == 27:
            break
    # 摄像头释放
    camera.release()
    # 销毁所有窗口
    cv2.destroyAllWindows()

    plt.figure('tracking')
    plt.plot(OB[0], OB[1])
    plt.plot(ES[0], ES[1])
    plt.legend(['观测轨迹', 'Kalman估计轨迹'])
    plt.grid(ls='-.')
    plt.show()

"""
data = []
    with open('1.txt') as f:
        for line in f:
            data.append([int(x) for x in line.split(",")])
    data = np.array(data)
    print(data)
    x0 = np.array([data[0][0], 0, data[0][1], 0])  # 初始位置
    kft = KFT(X = x0)
#    print(kft.id)
    x = x0
    for i in range(1,len(data)):
        (x1, p1) = kft.predict()
        vx = data[i][0] - data[i-1][0]
        vy = data[i][1] - data[i-1][1]
        z = np.array([data[i][0], vx, data[i][1], vy])
        (x, p, k) = kft.update(Z=z)
    XX = kft.getX()
    X = [z[0] for z in XX]
    Y = [z[2] for z in XX]
#    print(XX)

    plt.figure('ss')
    plt.plot(data.T[0], data.T[1])
    plt.plot(X, Y)
    plt.grid(ls='-.')
    plt.legend(['观测', 'KF估计'])
    plt.show()
"""
```

## *阈值选择

```python
# -*- coding:utf-8 -*-

import cv2
import numpy as np

"""
功能：读取一张图片，显示出来，转化为HSV色彩空间
     并通过滑块调节HSV阈值，实时显示
"""

image = cv2.imread('ora.jpg') # 根据路径读取一张图片
cv2.imshow("BGR", image) # 显示图片

hsv_low = np.array([0, 0, 0])
hsv_high = np.array([0, 0, 0])

# 下面几个函数，写得有点冗余

def h_low(value):
    hsv_low[0] = value

def h_high(value):
    hsv_high[0] = value

def s_low(value):
    hsv_low[1] = value

def s_high(value):
    hsv_high[1] = value

def v_low(value):
    hsv_low[2] = value

def v_high(value):
    hsv_high[2] = value

cv2.namedWindow('image',cv2.WINDOW_AUTOSIZE)
# 可以自己设定初始值，最大值255不需要调节
cv2.createTrackbar('H low', 'image', 35, 255, h_low)
cv2.createTrackbar('H high', 'image', 90, 255, h_high)
cv2.createTrackbar('S low', 'image', 43, 255, s_low)
cv2.createTrackbar('S high', 'image', 255, 255, s_high)
cv2.createTrackbar('V low', 'image', 35, 255, v_low)
cv2.createTrackbar('V high', 'image', 255, 255, v_high)

while True:
    dst = cv2.cvtColor(image, cv2.COLOR_BGR2HSV) # BGR转HSV
    dst = cv2.inRange(dst, hsv_low, hsv_high) # 通过HSV的高低阈值，提取图像部分区域
    cv2.imshow('dst', dst)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break
cv2.destroyAllWindows()
```

# 中期老师建议：

1、跟踪处理的速度

2、乒乓球、羽毛球，最快速度400km/h,快速问题

3、KCF比较2016，colorlam？，颜色名字



Q1:多色提取，多目标，自动提取？

Q2:高速运动



# 3

[OpenCV探索之路（二十二）：制作一个类“全能扫描王”的简易扫描软件 - Madcola - 博客园 (cnblogs.com)](https://www.cnblogs.com/skyfsm/p/7324346.html)有选取面积最大的轮廓算法



```python
def image_enhancement(image):
    '''图像增强，增强对比度和亮度
    image PIL'''
    # 对比度增强
    enh_con = ImageEnhance.Contrast(image)
    # contrast = 5
    image_contrasted = enh_con.enhance(10)
    # 亮度增强
    enh_bri = ImageEnhance.Brightness(image_contrasted)
    image_contrasted1 = cv2.cvtColor(np.asarray(image_contrasted), cv2.COLOR_RGB2BGR)  # PIL转cv2
    clear = getImageVar(image_contrasted1)
    # print(clear)
    brightness = max(round(clear / 2000, 1), 1)
    # print(brightness)
    image_brightened = enh_bri.enhance(brightness)
    return image_brightened

```

## 别人的改变图片尺寸的代码

```python
import os
import cv2
# 输入原始图像存在的文件夹
datadir = "XXX"
# 设置保存路径
save_path = 'XXX'
if not os.path.exists(save_path):#如果路径不存在
	os.makedirs(save_path)
# 输入你想要resize的图像尺寸。
size = 640 
# 获取原始图像宽高。
height, width = image.shape[0], image.shape[1]
# 等比例缩放尺度。
scale = height/size    # 1
# 获得相应等比例的图像宽度。
width_size = int(width/scale)  # 2
#使用os.path生成路径。
path = os.path.join(datadir)
#使用os.listdir返回path路径下所有图像文件。
img_list = os.listdir(path)
# 遍历图像文件
for i in img_list:
    img_array = cv2.imread(os.path.join(path, i), cv2.IMREAD_COLOR)
    # resize
    new_image = cv2.resize(img_array, (width_size, size))
    os.path.join(save_path, str(i)) # 保存的图片与原始图片同名
    #保存图片
    cv2.imwrite(save_path, new_image)

```

```python
import os
import cv2
# 输入原始图像存在的文件夹
datadir = "XXX"
# 设置保存路径
save_path = 'XXX'
if not os.path.exists(save_path):#如果路径不存在
	os.makedirs(save_path)
# 输入你想要resize的图像尺寸。
SIZE = 640
#使用os.path生成路径。
path = os.path.join(datadir)
#使用os.listdir返回path路径下所有图像文件。
img_list = os.listdir(path)
# 遍历图像文件
for i in img_list:
    img_array = cv2.imread(os.path.join(path, i), cv2.IMREAD_COLOR)
    # resize
    new_image = cv2.resize(img_array, (SIZE, SIZE))
    os.path.join(save_path, str(i)) # 保存的图片与原始图片同名
    #保存图片
    cv2.imwrite(save_path, new_image)

```

## 简单版（改变尺寸）

```python
import os
import cv2
# 输入原始图像存在的文件夹

SIZE = 400

img_array = cv2.imread('12.jpg')
    # resize
new_image = cv2.resize(img_array, (SIZE, SIZE))
#os.path.join(str('s12.jpg')) # 保存的图片与原始图片同名
    #保存图片
#cv2.imwrite(new_image)

cv2.namedWindow('img')
cv2.imshow('new_', new_image)
#cv2.imshow('new_', img_array)
cv2.waitKey(0)
"""
# 遍历图像文件
for i in img_list:
    img_array = cv2.imread(os.path.join(path, i), cv2.IMREAD_COLOR)
    # resize
    new_image = cv2.resize(img_array, (SIZE, SIZE))
    os.path.join(save_path, str(i)) # 保存的图片与原始图片同名
    #保存图片
    cv2.imwrite(save_path, new_image)
"""
```

![image-20221217203730810](草稿.assets/image-20221217203730810.png)

第一步，选择目标

第二步，选择下一步的采样位置

## *多目标的改进

```python
import cv2
import numpy as np
import matplotlib.pyplot as plt
from collections import deque
import time

iswrite = False#是否保存写入

class KFT():
    """
    一个卡尔曼滤波追踪器KalmanFilterTracker
    """
    count = 0



    def __init__(self, A=np.array([[1, 1, 0, 0],
                                   [0, 1, 0, 0],
                                   [0, 0, 1, 1],
                                   [0, 0, 0, 1]]),
                 B=np.array([0.5, 1, 0.5, 1]),
                 R=np.array([[0.1, 0, 0, 0],
                             [0, 0.1, 0, 0],
                             [0, 0, 0.1, 0],
                             [0, 0, 0, 0.1]]),
                 Q=np.array([[0.1, 0, 0, 0],
                             [0, 0.1, 0, 0],
                             [0, 0, 0.1, 0],
                             [0, 0, 0, 0.1]]),
                 H=np.eye(4),
                 U=np.array([0, 0, 0, 0]),
                 P=np.array([[0.1, 0, 0, 0],
                             [0, 0.1, 0, 0],
                             [0, 0, 0.1, 0],
                             [0, 0, 0, 0.1]]),
                 P1=np.array([[0.1, 0, 0, 0],
                              [0, 0.1, 0, 0],
                              [0, 0, 0.1, 0],
                              [0, 0, 0, 0.1]]),
                 K=np.array([0]),
                 X=np.array([0, 0, 0, 0]),
                 X1=np.array([0, 0, 0, 0])):
        self.id = KFT.count
        KFT.count += 1
        self.A = A
        self.B = B
        self.R = R
        self.Q = Q
        self.H = H
        self.U = U

        self.P = P
        self.P1 = P1
        self.K = K
        self.X = X
        self.X1 = X1

        self.X_all = [X]
        self.X1_all = [X1]

    def predict(self):
        #        print('-----------------------------------------------------------')

        self.X1 = np.dot(self.A, self.X_all[-1]) + np.dot(self.B, self.U)
        #        print('X1:\n', self.X1)
        self.P1 = np.dot(np.dot(self.A, self.P), self.A.T) + self.Q
        #        print('P1:\n',self.P1)
        self.X1_all.append(self.X1)
        return (self.X1, self.P1)

    def update(self, Z):  # 输入观测状态向量[x,0,y,0]
        self.K = np.dot(np.dot(self.P1, self.H.T), np.linalg.pinv(np.dot(np.dot(self.H, self.P1), self.H.T) + self.R))
        #        print('K:\n', self.K)
        #        print(np.dot(self.P1, self.H.T))
        #        print('*')
        #        print(np.dot(self.H, self.P1))
        #        print(np.dot(np.dot(self.H, self.P1), self.H.T))
        #        print(np.dot(np.dot(self.H, self.P1), self.H.T) + self.R)
        #        print(np.linalg.pinv(np.dot(np.dot(self.H, self.P1), self.H.T) + self.R))

        self.X = self.X1 + np.dot(self.K, Z - np.dot(self.H, self.X1))
        #        print('X:\n', self.X)
        self.P = np.dot(np.eye(self.K.shape[0]) - np.dot(self.K, self.H), self.P1)
        #        print('P:\n', self.P)
        self.X_all.append(self.X)
        #        print('-----------------------------------------------------------')
        return (self.X, self.P, self.K)

    def getX(self):
        return self.X_all


if __name__ == '__main__':
    plt.rcParams['font.sans-serif'] = ['SimHei']  # 设置图形里面中文为黑体


    # 设定阈值，HSV空间
    obj = [[[0, 142, 72], [21, 255, 255]], [[80, 84, 163], [123, 146, 249]]]
    num_of_objs = len(obj)#要追踪的物体个数

    OB = [[[], []], ] # 记录观测数据
    ES = [[[], []], ] # 记录估计数据

    s = [[], []]
    for i in range(num_of_objs - 1):
        OB.append(list(s))
        ES.append(list(s))

    redLower = np.array(obj[0][0])
    redUpper = np.array(obj[0][1])
    # 初始化追踪点的列表
    mybuffer = 64
    pts = deque(maxlen=mybuffer)
    # 打开摄像头
    camera = cv2.VideoCapture('12test.mp4')  # 'test.mp4'
    # 保存视频
    width = int(camera.get(cv2.CAP_PROP_FRAME_WIDTH))  # 获取视频的宽度
    height = int(camera.get(cv2.CAP_PROP_FRAME_HEIGHT))  # 获取视频的高度
    fps = camera.get(cv2.CAP_PROP_FPS)  # 获取视频的帧率
    fourcc = int(camera.get(cv2.CAP_PROP_FOURCC))  # 视频的编码
    # 定义视频对象输出
    if iswrite:
        writer = cv2.VideoWriter("result.mp4", fourcc, fps, (width, height))#200

    # 等待两秒
    time.sleep(2)
    # 遍历每一帧，检测红色瓶盖
    cnt = 0
    kfts = []#各自的kft
    lastx = [0 for i in range(num_of_objs)]
    lasty = [0 for i in range(num_of_objs)]
    while True:
        # 读取帧

        (ret, frame) = camera.read()
        if ret == False:
            break
        timer = cv2.getTickCount()
        # 判断是否成功打开摄像头
        # if not ret:
        #     print('No Camera')
        #     break
        # frame = imutils.resize(frame, width=600)
        # 转到HSV空间
        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)

        for i in range(num_of_objs):
            # 根据阈值构建掩膜
            mask = cv2.inRange(hsv, np.array(obj[i][0]), np.array(obj[i][1]))
            # 腐蚀操作
            mask = cv2.erode(mask, None, iterations=2)
            # 膨胀操作，其实先腐蚀再膨胀的效果是开运算，去除噪点
            mask = cv2.dilate(mask, None, iterations=2)
            # 轮廓检测
            cnts = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[-2]
            # 初始化瓶盖圆形轮廓质心
            center = None
            # 如果存在轮廓
            if len(cnts) > 0:
                # 找到面积最大的轮廓
                c = max(cnts, key=cv2.contourArea)
                # 确定面积最大的轮廓的外接圆
                ((x, y), radius) = cv2.minEnclosingCircle(c)
                # 计算轮廓的矩
                M = cv2.moments(c)
                # 计算质心
                center = (int(M["m10"] / M["m00"]), int(M["m01"] / M["m00"]))  # center为观测值

                OB[i][0].append(center[0])
                OB[i][1].append(center[1])

                if cnt == 0 or cnt == 1:  # 如果是首帧
                    x0 = np.array([center[0], 0, center[1], 0])  # 初始位置
                    kft = KFT(X=x0)
                    kfts.append(kft)
                    lastx[i] = center[0]
                    lasty[i] = center[1]
                    cnt += 1
                    continue

                (X1, P1) = kfts[i].predict()
                vx = center[0] - lastx[i]
                vy = center[1] - lasty[i]
                z = np.array([center[0], vx, center[1], vy])
                (X, P, K) = kfts[i].update(Z=z)

                # X就是最优估计

                lastx[i] = center[0]
                lasty[i] = center[1]

                esX = X[0]
                esY = X[2]

                ES[i][0].append(esX)
                ES[i][1].append(esY)
                # 只有当半径大于10时，才执行画图
                if radius > 10:
                    cv2.circle(frame, (int(x), int(y)), int(radius), (0, 255, 255), 2)
                    cv2.circle(frame, center, 2, (0, 0, 255), -1)
                    cv2.circle(frame, (int(esX), int(esY)), 2, (0, 0, 0), -1)  # 最优估计

                    # 把质心添加到pts中，并且是添加到列表左侧
                    pts.appendleft(center)
            """
                    for i in range(1, len(pts)):
                if pts[i - 1] is None or pts[i] is None:
                    continue
                # 计算所画小线段的粗细
                thickness = int(np.sqrt(mybuffer / float(i + 1)) * 2.5)
                # 画出小线段
                cv2.line(frame, pts[i - 1], pts[i], (0, 0, 255), thickness)
            # res = cv2.bitwise_and(frame, frame, mask=mask)
            """
            # 遍历追踪点，分段画出轨迹


        fps = cv2.getTickFrequency() / (cv2.getTickCount() - timer)
        cv2.putText(frame, "FPS : " + str(int(fps)), (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (50, 170, 50), 1)
        # cv2.putText(frame, ":kalman est " + str(int(fps)), (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 0), 1)
        cv2.imshow('Frame', frame)
        if iswrite:
            writer.write(frame)  # 视频保存
        # 键盘检测，检测到esc键退出
        k = cv2.waitKey(5) & 0xFF
        if k == 27:
            break
    # 摄像头释放
    camera.release()
    # 销毁所有窗口
    cv2.destroyAllWindows()

    plt.figure('tracking')
    for i in range(num_of_objs):
        plt.plot(OB[i][0], OB[i][1], label = '观测轨迹{}'.format(i))
        plt.plot(ES[i][0], ES[i][1], label = 'Kalman估计轨迹{}'.format(i))
        #plt.legend(['观测轨迹', 'Kalman估计轨迹'])
    plt.legend()
    plt.grid(ls='-.')
    plt.show()

"""
data = []
    with open('1.txt') as f:
        for line in f:
            data.append([int(x) for x in line.split(",")])
    data = np.array(data)
    print(data)
    x0 = np.array([data[0][0], 0, data[0][1], 0])  # 初始位置
    kft = KFT(X = x0)
#    print(kft.id)
    x = x0
    for i in range(1,len(data)):
        (x1, p1) = kft.predict()
        vx = data[i][0] - data[i-1][0]
        vy = data[i][1] - data[i-1][1]
        z = np.array([data[i][0], vx, data[i][1], vy])
        (x, p, k) = kft.update(Z=z)
    XX = kft.getX()
    X = [z[0] for z in XX]
    Y = [z[2] for z in XX]
#    print(XX)

    plt.figure('ss')
    plt.plot(data.T[0], data.T[1])
    plt.plot(X, Y)
    plt.grid(ls='-.')
    plt.legend(['观测', 'KF估计'])
    plt.show()
"""
```

**阈值的自动选择，遮挡问题的卡尔曼预测，**

1、先选择多个ROI，阈值自动分割，并记录阈值；

2、卡尔曼预测下一个采样框（可提升效率，也可避免两个橘子的问题），框中计算质心，

3、即将重叠时判断为遮挡，进行卡尔曼轨迹预测

## 将hsvpick写成类

```python
# -*- coding:utf-8 -*-
import cv2
import numpy as np
"""
功能：读取一张图片，显示出来，转化为HSV色彩空间
     并通过滑块调节HSV阈值，实时显示
"""

image = cv2.imread('5.jpg') # 根据路径读取一张图片
cv2.imshow("BGR", image) # 显示图片
hsv_low = np.array([0, 0, 0])
hsv_high = np.array([0, 0, 0])
def h_low(value):
    hsv_low[0] = value
def h_high(value):
    hsv_high[0] = value
def s_low(value):
    hsv_low[1] = value
def s_high(value):
    hsv_high[1] = value
def v_low(value):
    hsv_low[2] = value
def v_high(value):
    hsv_high[2] = value
cv2.namedWindow('image',0)
cv2.createTrackbar('H low', 'image', 35, 255, h_low)
cv2.createTrackbar('H high', 'image', 90, 255, h_high)
cv2.createTrackbar('S low', 'image', 43, 255, s_low)
cv2.createTrackbar('S high', 'image', 255, 255, s_high)
cv2.createTrackbar('V low', 'image', 35, 255, v_low)
cv2.createTrackbar('V high', 'image', 255, 255, v_high)
while True:
    dst = cv2.cvtColor(image, cv2.COLOR_BGR2HSV) # BGR转HSV
    dst = cv2.inRange(dst, hsv_low, hsv_high) # 通过HSV的高低阈值，提取图像部分区域
    cv2.imshow('dst', dst)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break
final = np.array[hsv_low, hsv_high]
cv2.destroyAllWindows()
```

## 颜色相近

阈值检测不唯一的改进思路：![image-20221228171014024](草稿.assets/image-20221228171014024.png)





## 四个问题：

（尺度问题）非刚性变形，遮挡，目标脱离视野和背景杂波

新：部分遮挡，采样框

## fps

kcf的帧率：

![image-20221229172529959](草稿.assets/image-20221229172529959.png)

我们的（数据集较为简单）：

![image-20221229172613883](草稿.assets/image-20221229172613883.png)

还剩部分遮挡和背景杂波的解决方式。

目前思路：部分遮挡，检测识别到的物体是否是原来的形状

背景杂波：根据选择的hsv阈值通过一个公式得出一个值，（显然阈值越大，背景杂波越强，），通过该值结合位置的概率滤掉杂波.

或者增加腐蚀次数。



自适应。

## 流程图

![image-20230106231325344](草稿.assets/image-20230106231325344.png)

## 要说的话：

代码流程



四个问题的解决

采样框的好处和坏处，好处：一定程度排除背景干扰——目标丢失视野，剪辑——方法：产生多个采样框去监测一个物体。

采样框应至少框住物体，

新问题，容易被晃飞。

采样框丢失处理：1、首帧很关键，考虑第三帧加入采样框，有速率信息。缺点是丢失两帧信息，那每次丢失视野都得重复这种操作，预计会丢失很多信息。2、考虑放大处理，放大倍数又成了一个问题，3、多个采样框，4、采用了直接全视野寻找。

总结：

在纯色物体和目标连续的视频场景下效果较好，卡尔曼滤波主要用于处理遮挡问题.

缺点：依赖首帧，场景，目标受限，误差受阈值影响较大。



多目标问题，互相遮挡

KCF和我的对比

KCF能适应物体的变化



对于估计越界的问题，是由于物体在边界时被遮挡造成的，会被误认为朝框外飞去，这本身就不好判断，所以保守估计，将其设置为边框数值

